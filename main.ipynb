{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b92a2c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_google_genai import GoogleGenerativeAI, GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, BaseMessage, ToolMessage, AIMessage\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.output_parsers.string import StrOutputParser\n",
    "from langchain_core.output_parsers import BaseOutputParser\n",
    "from langchain_core.runnables import chain\n",
    "from langchain_core.documents import Document\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_core.tools import tool\n",
    "from pydantic import BaseModel\n",
    "from typing import Annotated, List, Sequence, Optional\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "import bs4\n",
    "from dotenv import load_dotenv\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1494f163",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(\".env\")\n",
    "GG_API_KEY = os.environ.get('GOOGLE_API_KEY')\n",
    "PINECONE_API_KEY = os.environ.get('PINECONE_API_KEY')\n",
    "LANGSMITH_API_KEY = os.environ.get('LANGSMITH_API_KEY')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10d9c1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = WebBaseLoader(\n",
    "    web_path=\"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
    "    bs_kwargs={'parse_only' : bs4.SoupStrainer(class_=(\"post-content\", \"post-title\", \"post-header\"))}\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "# Split documents\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "all_splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04ec5d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mac/Desktop/Code/Personal_Project/DeepLearningProject/RAG_Project/rag_env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Set up vector database\n",
    "\n",
    "import time\n",
    "import os\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "index_name = \"ragfinance\"  # change if desired\n",
    "\n",
    "existing_indexes = [index_info[\"name\"] for index_info in pc.list_indexes()]\n",
    "\n",
    "if index_name not in existing_indexes:\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=768,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"),\n",
    "        deletion_protection=\"enabled\",  # Defaults to \"disabled\"\n",
    "    )\n",
    "    while not pc.describe_index(index_name).status[\"ready\"]:\n",
    "        time.sleep(1)\n",
    "\n",
    "index = pc.Index(index_name)\n",
    "vector_store = PineconeVectorStore(index=index, embedding=GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7b21e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store.delete(delete_all=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d23a1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = vector_store.add_documents(all_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f9555cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiHeirttTask.py FinQATask.py FinanceBenchTask.py ConvFinQATask.py FinQABenchTask.py TATQATask.py FinDERTask.py "
     ]
    }
   ],
   "source": [
    "modules = []\n",
    "for f in os.listdir('finance_dataset'):\n",
    "    if f.endswith('tsv'):\n",
    "        python_module = f.split(\"_\")[0] + \"Task.py\"\n",
    "        modules.append(python_module)\n",
    "for module in modules:\n",
    "    print(module, end = \" \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81599e9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(id='d4aa10922', metadata={'dataset_name': 'finqabench'}, page_content=' 2031 Notes).\\n7'),\n",
       "  0.562556505),\n",
       " (Document(id='d4aa1b854', metadata={'dataset_name': 'finqabench'}, page_content='• in the case of the 2018 Indenture, to add to, change or eliminate any of the provisions of the 2018 Indenture in respect of one or more series of debt securities; provided that any such addition, change or elimination shall become effective only when there is no outstanding security of any series created prior to the execution of such supplemental indenture that is entitled to the benefit of such provision and as to which such supplemental indenture would apply; • to cure any ambiguity, omission, defect or inconsistency; • to change any other provision; provided that the change does not adversely affect the interests of the holders of debt securities of, in the case of the 2013 Indenture any series, and in the case of the 2018 Indenture, any outstanding series, in any material respect; • to supplement any of the provisions of the applicable Indenture to such extent as shall be necessary to permit or facilitate the defeasance and discharge of any series of Notes pursuant to the Indenture; 12 provided that any such action shall not adversely affect the interests of the holders of Notes of such series or any other series of debt securities in any material respect; • to comply with the rules or regulations of any securities exchange or automated quotation system on which any of the Notes may be listed or traded; and • to add to, change or eliminate any of the provisions of the applicable Indenture as shall be necessary or desirable in accordance with any amendments to the Trust Indenture Act of 1939, as amended, and in the case of the 2013 Indenture, provided that such action does not adversely affect the rights or interests of any holder of debt securities in any material respect. The holders of at least a majority in aggregate principal amount of the outstanding Notes of any series may, on behalf of the holders of all Notes of that series, waive compliance by us with certain restrictive provisions of the Indentures. The holders of not less than a majority in aggregate principal amount of the outstanding Notes of a series may, on behalf of the holders of all Notes of that series, waive any past default and its consequences under the applicable Indenture with respect to the Notes of that series, except a default (1) in the payment of principal or premium, if any, or interest on Notes of that series or (2) in respect of a covenant or provision of the applicable Indenture that cannot be modified or amended without the consent of the holder of each Note of that series. Upon any such waiver, such default will cease to exist, and any event of default arising therefrom will be deemed to have been cured, for every purpose of the Indenture; however, no such waiver will extend to any subsequent or other default or event of default or impair any rights consequent thereon. Discharge, Defeasance and Covenant Defeasance We may discharge certain obligations to holders of the Notes of a series that have not already been delivered to the trustee for cancellation and that either have become due and payable or will become due and payable within one year (or scheduled for redemption within one year) by depositing with the trustee, in trust, funds in U.S. dollars in an amount sufficient to pay the entire indebtedness including, but not limited to, the principal and premium, if any, and interest to the date of such deposit (if due and payable) or to the maturity thereof or the redemption date of the Notes of that series, as the case may be. We may direct the trustee to invest such funds in U.S. Treasury securities with a maturity of one year or less or in a money market fund that invests solely in short-term U.S. Treasury securities. The Indentures provide that we may elect either (1) to defease and be discharged from any and all obligations with respect to the Notes of a series (except for, among other things, obligations to register the transfer or exchange of the Notes, to replace temporary or mutilated, destroyed, lost or stolen Notes, to maintain an office or agency with respect to the Notes and to hold moneys for payment in trust) (“legal defeasance”) or (2) to be released from our obligations to comply with the restrictive covenants under the applicable Indenture, and any omission to comply with such obligations will not constitute a default or an event of default with respect to the Notes of a series and clauses (3) and (6) under the caption “Events of Default” above will no longer be applied (“covenant defeasance”). Legal defeasance or covenant defeasance, as the case may be, will be conditioned upon, among other things, the irrevocable deposit by us with the trustee, in trust, of an amount in U.S. dollars, or U.S. government obligations (as such term is modified below), or both, applicable to the Notes of that series which through the scheduled payment of principal and interest in accordance with their terms will provide money in an amount sufficient to pay the principal or premium, if any, and interest on the Notes on the scheduled due dates therefor. If we effect covenant defeasance with respect to the Notes of any series, the amount in U.S. dollars, or U.S. government obligations (as such term is modified below), or both, on deposit with the trustee will be sufficient, in the opinion of a nationally recognized firm of independent accountants, to pay amounts due on the Notes of that series at the time of the stated maturity but may not be sufficient to pay amounts due on the Notes of that series at the time of the acceleration resulting from such event of default. However, we would remain liable to make payment of such amounts due at the time of acceleration. With respect to the 2022 Notes, the 2024 Notes, the 0.000% 2025 Notes, the 0.875% 2025 Notes, the 2026 Notes, the 2027 Notes, the 1.375% 2029 Notes and the 2031 Notes, the term “U.S. government obligations” shall instead mean (x) any security that is (i) a direct obligation of the German government or (ii) an obligation of a person controlled or supervised by and acting as an agency or instrumentality of the German government the payment of which is fully and unconditionally guaranteed by the German government or the central bank of the German government, which, in either case (x)(i) or (ii), is not callable or redeemable at the option of the issuer thereof, and (y) 13 certificates, depositary receipts or other instruments which evidence a direct ownership interest in obligations described in clause (x)(i) or (x)(ii) above or in any specific principal or interest payments due in respect thereof. With respect to the 3.050% 2029 Notes and the 2042 Notes, the term “U.S. government obligations” shall instead mean (x) any security that is (i) a direct obligation of the United Kingdom government or (ii) an obligation of a person controlled or supervised by and acting as an agency or instrumentality of the United Kingdom government the payment of which is fully and unconditionally guaranteed by the United Kingdom government or the central bank of the United Kingdom government, which, in either case (x)(i) or (ii), is not callable or redeemable at the option of the issuer thereof, and (y) certificates, depositary receipts or other instruments which evidence a direct ownership interest in obligations described in clause (x)(i) or (x)(ii) above or in any specific principal or interest payments due in respect thereof. We will be required to deliver to the trustee an opinion of counsel that the deposit and related defeasance will not cause the holders and beneficial owners of the Notes of that series to recognize income, gain or loss for federal income tax purposes. If we elect legal defeasance, that opinion of counsel must be based upon a ruling from the U.S. Internal Revenue Service or a change in law to that effect. We may exercise our legal defeasance option notwithstanding our prior exercise of our covenant defeasance option. Book-Entry and Settlement The Notes were issued in book-entry form and are represented by global notes deposited with, or on behalf of, a common depositary on behalf of Euroclear and Clearstream, and are registered in the name of the common depositary or its nominee. Except as described herein, certificated notes will not be issued in exchange for beneficial interests in the global notes. Certificated Notes Subject to certain conditions, the Notes represented by the global notes are exchangeable for certificated notes in definitive form of like tenor, in minimum denominations of €100,000 principal amount and integral multiples of €1,000 in excess thereof in the case of the 2022 Notes, the 2024 Notes, the 0.000% 2025 Notes, the 0.875% 2025 Notes, the 2026 Notes, the 2027 Notes, the 1.375% 2029 Notes and the 2031 Notes, and in minimum denominations of £100,000 principal amount and integral multiples of £1,000 in excess thereof in the case of the 3.050% 2029 Notes and the 2042 Notes, if: 1. the common depositary notifies us that it is unwilling or unable to continue as depositary or'),\n",
       "  0.559459865),\n",
       " (Document(id='d4aa05ebe', metadata={'dataset_name': 'finqabench'}, page_content='cancelable obligations related to internet services and content creation. As of \\nSeptember\\xa024, 2022 , the Company had other purchase obligations of $17.8 billion, with $6.8 billion payable within 12 months.\\nDeemed Repatriation Tax Payable\\nAs of September\\xa024, 2022 , the balance of the deemed repatriation tax payable imposed by the U.S. Tax Cuts and Jobs Act of \\n2017 (the “Act”) was $22.0\\xa0billion , with $5.3\\xa0billion  expected to be paid within 12 months.\\nIn addition to its contractual cash requirements, the Company has a capital return program authorized by the Board of Directors . \\nThe Program does not obligate the Company to acquire a minimum amount of shares. As of September\\xa0 24, 2022 , the \\nCompany’s quarterly cash dividend was $0.23  per share. The Company intends to increase its dividend on an annual'),\n",
       "  0.55880177),\n",
       " (Document(id='dd2af3272', metadata={'dataset_name': 'financebench'}, page_content='Note 3 Restructuring and Impairment Charges\\n2019 Multi-Year Productivity Plan\\nWe publicly announced a multi-year productivity plan on February 15, 2019 (2019 Productivity Plan) that will leverage new\\ntechnology and business models to further simplify, harmonize and automate processes; re-engineer our go-to-market and\\ninformation systems, including deploying the right automation for each market; and simplify our organization and optimize our\\nmanufacturing and supply chain footprint. To build on the successful implementation of the 2019 Productivity Plan, in the fourth\\nquarter of 2022, we expanded and extended the plan through the end of 2028 to take advantage of additional opportunities within\\nthe initiatives described above. As a result, we expect to incur pre-tax charges of approximately $3.65 billion, including cash\\nexpenditures of approximately $2.9 billion. These pre-tax charges are expected to consist of approximately 55% of severance and\\nother employee-related costs, 10% for asset impairments (all non-cash) resulting from plant closures and related actions and 35%\\nfor other costs associated with the implementation of our initiatives.\\nThe total plan pre-tax charges are expected to be incurred by division approximately as follows:\\nFLNA\\nQFNA\\nPBNA\\nLatAm\\nEurope\\nAMESA\\nAPAC\\nCorporate\\nExpected pre-tax charges\\n15 %\\n1 %\\n25 %\\n10 %\\n25 %\\n5 %\\n4 %\\n15 %\\nA summary of our 2019 Productivity Plan charges is as follows:\\n2022\\n2021\\n2020\\nCost of sales\\n$\\n33 \\n$\\n29 $\\n30 \\nSelling, general and administrative expenses\\n347 \\n208 \\n239 \\nOther pension and retiree medical benefits expense\\n31 \\n10 \\n20 \\nTotal restructuring and impairment charges\\n$\\n411 \\n$\\n247 $\\n289'),\n",
       "  0.553177416)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.similarity_search_with_score(\"task-decompositoin\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c911bc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(model = \"gemini-2.0-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ecd5f49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='1fb679d5-a736-4ce9-9766-d8f933a1e5b6', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='GOALS:\\n\\n1. {{user-provided goal 1}}\\n2. {{user-provided goal 2}}\\n3. ...\\n4. ...\\n5. ...\\n\\nConstraints:\\n1. ~4000 word limit for short term memory. Your short term memory is short, so immediately save important information to files.\\n2. If you are unsure how you previously did something or want to recall past events, thinking about similar events will help you remember.\\n3. No user assistance\\n4. Exclusively use the commands listed in double quotes e.g. \"command name\"\\n5. Use subprocesses for commands that will not terminate within a few minutes'),\n",
       " Document(id='cbf3a36b-5718-4c95-8730-5b4eec1ff508', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='HNSW (Hierarchical Navigable Small World): It is inspired by the idea of small world networks where most nodes can be reached by any other nodes within a small number of steps; e.g. “six degrees of separation” feature of social networks. HNSW builds hierarchical layers of these small-world graphs, where the bottom layers contain the actual data points. The layers in the middle create shortcuts to speed up search. When performing a search, HNSW starts from a random node in the top layer and navigates towards the target. When it can’t get any closer, it moves down to the next layer, until it reaches the bottom layer. Each move in the upper layers can potentially cover a large distance in the data space, and each move in the lower layers refines the search quality.'),\n",
       " Document(id='7b5ea39c-51f7-4484-8629-2d04f24e0846', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Illustration of the Reflexion framework. (Image source: Shinn & Labash, 2023)\\n\\nThe heuristic function determines when the trajectory is inefficient or contains hallucination and should be stopped. Inefficient planning refers to trajectories that take too long without success. Hallucination is defined as encountering a sequence of consecutive identical actions that lead to the same observation in the environment.\\nSelf-reflection is created by showing two-shot examples to LLM and each example is a pair of (failed trajectory, ideal reflection for guiding future changes in the plan). Then reflections are added into the agent’s working memory, up to three, to be used as context for querying LLM.\\n\\n\\nExperiments on AlfWorld Env and HotpotQA. Hallucination is a more common failure than inefficient planning in AlfWorld. (Image source: Shinn & Labash, 2023)'),\n",
       " Document(id='790286d1-e1fe-4e77-8ffa-7d9bfed18118', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='(2) Model selection: LLM distributes the tasks to expert models, where the request is framed as a multiple-choice question. LLM is presented with a list of models to choose from. Due to the limited context length, task type based filtration is needed.\\nInstruction:\\n\\nGiven the user request and the call command, the AI assistant helps the user to select a suitable model from a list of models to process the user request. The AI assistant merely outputs the model id of the most appropriate model. The output must be in a strict JSON format: \"id\": \"id\", \"reason\": \"your detail reason for the choice\". We have a list of models for you to choose from {{ Candidate Models }}. Please select one model from the list.\\n\\n(3) Task execution: Expert models execute on the specific tasks and log results.\\nInstruction:')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@chain\n",
    "def retriever(query : str) -> List[Document]:\n",
    "    retrieved_docs = vector_store.similarity_search(query = query, k = 4)\n",
    "    return retrieved_docs\n",
    "retriever.invoke(\"helo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fee40a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(id='cbf3a36b-5718-4c95-8730-5b4eec1ff508', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='HNSW (Hierarchical Navigable Small World): It is inspired by the idea of small world networks where most nodes can be reached by any other nodes within a small number of steps; e.g. “six degrees of separation” feature of social networks. HNSW builds hierarchical layers of these small-world graphs, where the bottom layers contain the actual data points. The layers in the middle create shortcuts to speed up search. When performing a search, HNSW starts from a random node in the top layer and navigates towards the target. When it can’t get any closer, it moves down to the next layer, until it reaches the bottom layer. Each move in the upper layers can potentially cover a large distance in the data space, and each move in the lower layers refines the search quality.'), Document(id='7b6fdf31-ab24-44f3-96ed-c31a5ae62d5a', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='inquired about current trends in anticancer drug discovery;\\nselected a target;\\nrequested a scaffold targeting these compounds;\\nOnce the compound was identified, the model attempted its synthesis.')]\n"
     ]
    }
   ],
   "source": [
    "user_query = \"your search query here\"\n",
    "retrieved_documents = retriever(user_query)\n",
    "print(retrieved_documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2e98939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['How to break down a complex task?',\n",
       " 'What are the methods for dividing a task into smaller subtasks?',\n",
       " 'Explain the concept of task decomposition.',\n",
       " 'What is the process of breaking down tasks into manageable parts?',\n",
       " 'What are the benefits of using task decomposition techniques?']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QUERY_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"\"\"You are an AI language model assistant. Your task is to generate five \n",
    "    different versions of the given user question to retrieve relevant documents from a vector \n",
    "    database. By generating multiple perspectives on the user question, your goal is to help\n",
    "    the user overcome some of the limitations of the distance-based similarity search. \n",
    "    Provide these alternative questions separated by newlines. Remember to provide questions only, no additional text!\n",
    "    Original question: {question}\"\"\",\n",
    ")\n",
    "class ListOutputParser(BaseOutputParser):\n",
    "    def parse(self, text : str) -> List[str]:\n",
    "        lines = text.strip().split(\"\\n\")\n",
    "        return list(filter(None, lines))\n",
    "output_parser = ListOutputParser()\n",
    "chain = QUERY_PROMPT | llm | output_parser\n",
    "lines = chain.invoke({'question' : \"What is task-decomposition?\"})\n",
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9f3fa3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='4cdf6d41-c363-4d86-befa-c9b5f4c9c08a', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Component One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.'),\n",
       " Document(id='5fccb775-d2c8-47ee-afff-d957d11e9d84', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\nAnother quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\\nSelf-Reflection#'),\n",
       " Document(id='a9f3b7ce-8853-413f-80ed-d70d32a2a529', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Illustration of how HuggingGPT works. (Image source: Shen et al. 2023)\\n\\nThe system comprises of 4 stages:\\n(1) Task planning: LLM works as the brain and parses the user requests into multiple tasks. There are four attributes associated with each task: task type, ID, dependencies, and arguments. They use few-shot examples to guide LLM to do task parsing and planning.\\nInstruction:'),\n",
       " Document(id='2e401520-fe85-44bd-bf60-6a0d6e9792dd', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='\"content\": \"Please now remember the steps:\\\\n\\\\nThink step by step and reason yourself to the right decisions to make sure we get it right.\\\\nFirst lay out the names of the core classes, functions, methods that will be necessary, As well as a quick comment on their purpose.\\\\n\\\\nThen you will output the content of each file including ALL code.\\\\nEach file must strictly follow a markdown code block format, where the following tokens must be replaced such that\\\\nFILENAME is the lowercase file name including the file extension,\\\\nLANG is the markup code block language for the code\\'s language, and CODE is the code:\\\\n\\\\nFILENAME\\\\n```LANG\\\\nCODE\\\\n```\\\\n\\\\nPlease note that the code should be fully functional. No placeholders.\\\\n\\\\nYou will start with the \\\\\"entrypoint\\\\\" file, then go to the ones that are imported by that file, and so on.\\\\nFollow a language and framework appropriate best practice file naming convention.\\\\nMake sure that files contain all imports, types etc. The code should be fully'),\n",
       " Document(id='bb70e756-0ec5-458f-9ed0-fc309c835bd4', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content=\"(3) Task execution: Expert models execute on the specific tasks and log results.\\nInstruction:\\n\\nWith the input and the inference results, the AI assistant needs to describe the process and results. The previous stages can be formed as - User Input: {{ User Input }}, Task Planning: {{ Tasks }}, Model Selection: {{ Model Assignment }}, Task Execution: {{ Predictions }}. You must first answer the user's request in a straightforward manner. Then describe the task process and show your analysis and model inference results to the user in the first person. If inference results contain a file path, must tell the user the complete file path.\"),\n",
       " Document(id='e7961733-1685-483b-90c8-a85f3ec9917a', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='},\\n  {\\n    \"role\": \"user\",\\n    \"content\": \"We are writing {{a Super Mario game in python. MVC components split in separate files. Keyboard control.}}\\\\n\"\\n  },\\n  {\\n    \"role\": \"assistant\",\\n    \"content\": \"Summary of areas that need clarification:\\\\n1. Specifics of the Super Mario game (e.g. level design, characters, gameplay mechanics)\\\\n2. Details about the MVC components (e.g. which components are in each file)\\\\n3. Keyboard control implementation (e.g. which keys to use, how to handle input)\\\\n\\\\nClarifying question:\\\\nCan you provide more details about the Super Mario game, such as level design, characters, and gameplay mechanics?\"\\n  },\\n  {\\n    \"role\": \"user\",'),\n",
       " Document(id='54c1e451-c3d1-44c6-8c17-95773f46f20e', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='(4) Response generation: LLM receives the execution results and provides summarized results to users.\\nTo put HuggingGPT into real world usage, a couple challenges need to solve: (1) Efficiency improvement is needed as both LLM inference rounds and interactions with other models slow down the process; (2) It relies on a long context window to communicate over complicated task content; (3) Stability improvement of LLM outputs and external model services.'),\n",
       " Document(id='34fd9963-869b-4b28-aaaf-424655a1806a', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='\"content\": \"You will get instructions for code to write.\\\\nYou will write a very long answer. Make sure that every detail of the architecture is, in the end, implemented as code.\\\\nMake sure that every detail of the architecture is, in the end, implemented as code.\\\\n\\\\nThink step by step and reason yourself to the right decisions to make sure we get it right.\\\\nYou will first lay out the names of the core classes, functions, methods that will be necessary, as well as a quick comment on their purpose.\\\\n\\\\nThen you will output the content of each file including ALL code.\\\\nEach file must strictly follow a markdown code block format, where the following tokens must be replaced such that\\\\nFILENAME is the lowercase file name including the file extension,\\\\nLANG is the markup code block language for the code\\'s language, and CODE is the code:\\\\n\\\\nFILENAME\\\\n```LANG\\\\nCODE\\\\n```\\\\n\\\\nYou will start with the \\\\\"entrypoint\\\\\" file, then go to the ones that are imported by that file, and so on.\\\\nPlease')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def reciprocal_rank_fusion(results : List[List[Document]]) -> List[Document]:\n",
    "    # docs_dict: key = doc_id, value = doc.page_content\n",
    "    # rrf_score_dict : key = doc_id, value = score\n",
    "    docs_dict, rrf_score_dict = {}, {}\n",
    "    k = 60\n",
    "    for query_docs in results:\n",
    "        for rank, doc in enumerate(query_docs):\n",
    "            docs_dict[doc.id] = doc\n",
    "            rrf_score = 1 / (rank + 1 + k) # Calculatin reciprocal rank fusion score\n",
    "            if (doc.id not in rrf_score_dict.keys()):\n",
    "                rrf_score_dict[doc.id] = 0\n",
    "            rrf_score_dict[doc.id] += rrf_score\n",
    "    \n",
    "    # Sort by rrf_score\n",
    "    sorted_docs_by_rrf_score = sorted(rrf_score_dict.items(), key = lambda kv : kv[1], reverse = True)\n",
    "\n",
    "    fusion_docs = []\n",
    "    # Construct final document\n",
    "    for doc_id, _ in sorted_docs_by_rrf_score:\n",
    "        fusion_docs.append(docs_dict[doc_id])\n",
    "    return fusion_docs\n",
    "\n",
    "rag_fusion_chain = retriever.map() | reciprocal_rank_fusion\n",
    "rag_fusion_chain.invoke(lines)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb2b2a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f878c214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rerank document using cross-encoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d25f46ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import tools_condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00dfa7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are a helpful participant. Remember not to generate the answer in the markdown format!\"\n",
    "prompt = ChatPromptTemplate([\n",
    "    ('system', system_message),\n",
    "    MessagesPlaceholder('messages'),\n",
    "\n",
    "]\n",
    ")\n",
    "runnable = prompt | llm\n",
    "class State(TypedDict):\n",
    "    messages : Annotated[Sequence[BaseMessage], add_messages]\n",
    "\n",
    "\n",
    "# Defining tool for using RAG\n",
    "@tool(response_format=\"content_and_artifact\")\n",
    "def retrieve(query):\n",
    "    \"\"\"Used to retrieve external knowledge when the \n",
    "    LLM doesn't know the exact answer (RAG)\"\"\"\n",
    "    retrieved_docs = retriever.invoke(query)\n",
    "    serialized_docs = \"\\n\\n\".join([docs.page_content for docs in retrieved_docs])\n",
    "    return serialized_docs, retrieved_docs\n",
    " \n",
    "tools = ToolNode(tools = [retrieve])\n",
    "\n",
    "def query_or_respond(state : State):\n",
    "    \"\"\"Query for external knowledge or respond immediately\"\"\"\n",
    "    llm_with_tools = llm.bind_tools([retrieve])\n",
    "    response = llm_with_tools.invoke(state['messages'])\n",
    "    return {'messages' : [response]}\n",
    "\n",
    "def router(state : State):\n",
    "    last_message = state['messages'][-1]\n",
    "    if isinstance(last_message, AIMessage) and last_message.tool_calls:\n",
    "        return 'tools'\n",
    "    else:\n",
    "        return END\n",
    "\n",
    "# Create graph\n",
    "def generate(state : State):\n",
    "    # Only call this function when the previous message is tool message\n",
    "    tool_messages = []\n",
    "    messages = state['messages']\n",
    "    for message in reversed(messages):\n",
    "        if message.type == 'tool':\n",
    "            tool_messages.append(message)\n",
    "        else:\n",
    "            break\n",
    "    # Extract context from tool messages\n",
    "    context = \"\\n\\n\".join([message.content for message in tool_messages])\n",
    "    rag_prompt = f\"\"\"You are a question-answering assistent. If you don't know the answer, just\n",
    "    say \"I don't know\". Otherwise, your answer should be relevant to the questions and concise. \n",
    "    Use this context to answer my question: {context}.\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract conversation messages only\n",
    "    conversation_message = [message for message in messages if message.type in ('human', 'system')\n",
    "                            or (message.type in 'ai' and not message.tool_calls)]\n",
    "    final_messages = [SystemMessage(rag_prompt)] + conversation_message\n",
    "    response = runnable.invoke(final_messages)\n",
    "    return {'messages' : [response]}\n",
    "\n",
    "workflow = StateGraph(State)\n",
    "workflow.add_node(query_or_respond)\n",
    "workflow.add_node(tools)\n",
    "workflow.add_node(generate)\n",
    "\n",
    "\n",
    "workflow.set_entry_point('query_or_respond')\n",
    "workflow.add_conditional_edges('query_or_respond', path = router, path_map = {END : END, 'tools' : 'tools'})\n",
    "workflow.add_edge('tools', 'generate')\n",
    "workflow.add_edge('generate', END)\n",
    "# Add memory\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)\n",
    "\n",
    "app = workflow.compile()\n",
    "\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "3deaf021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(app.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7b9179",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\" : {'thread_id' : \"12ab\"}}\n",
    "\n",
    "\n",
    "# Do normal chatflow\n",
    "while(True):\n",
    "    question = input(\"Question:\")\n",
    "    if question.lower() in ['exit', 'quit', 'break', 'out']:\n",
    "        break\n",
    "    print(f\"Human: {question} \\n\")\n",
    "\n",
    "\n",
    "    # Create streaming message \n",
    "    for message_chunk, metadata in app.stream(\n",
    "        {'messages' : [HumanMessage(question)]}, stream_mode = 'messages', config = config\n",
    "    ):\n",
    "\n",
    "        if isinstance(message_chunk, AIMessage) and message_chunk.content:\n",
    "            print(message_chunk.content, end = \"\", flush = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43636dc",
   "metadata": {},
   "source": [
    "# Multiple query and RAG-Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158dc78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate multiple queries\n",
    "# system_multiple_queries = \"\"\"\n",
    "# You are an excellent rephraser. You job is to generate 4 queries that have equivalent meaning to my original query.\n",
    "# Remember to list the queries only, no external messages or any markdown format!\n",
    "# \"\"\"\n",
    "\n",
    "QUERY_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"\"\"You are an AI language model assistant. Your task is to generate five \n",
    "    different versions of the given user question to retrieve relevant documents from a vector \n",
    "    database. By generating multiple perspectives on the user question, your goal is to help\n",
    "    the user overcome some of the limitations of the distance-based similarity search. \n",
    "    Provide these alternative questions separated by newlines.\n",
    "    Original question: {question}\"\"\",\n",
    ")\n",
    "\n",
    "chain = QUERY_PROMPT | llm \n",
    "result = chain.invoke({'question' : \"What is task-decomposition?\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0069fe70",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ListOutputParser(BaseOutputParser):\n",
    "    def parse(self, text : str) -> List[str]:\n",
    "        lines = text.strip().split(\"\\n\")\n",
    "        return list(filter(None, lines))\n",
    "output_parser = ListOutputParser()\n",
    "lines = output_parser.invoke(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "351507b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_retriever = retriever.map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3764c2a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Document(id='e8c5ef63-cdfa-4cd1-ab93-810c333cc4db', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Component One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.'),\n",
       "  Document(id='7e717c8e-2008-41c4-a1c0-d892d1df4bb8', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\nAnother quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\\nSelf-Reflection#')],\n",
       " [Document(id='e8c5ef63-cdfa-4cd1-ab93-810c333cc4db', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Component One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.'),\n",
       "  Document(id='7e717c8e-2008-41c4-a1c0-d892d1df4bb8', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\nAnother quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\\nSelf-Reflection#')],\n",
       " [Document(id='7e717c8e-2008-41c4-a1c0-d892d1df4bb8', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\nAnother quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\\nSelf-Reflection#'),\n",
       "  Document(id='e8c5ef63-cdfa-4cd1-ab93-810c333cc4db', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Component One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.')],\n",
       " [Document(id='e8c5ef63-cdfa-4cd1-ab93-810c333cc4db', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Component One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.'),\n",
       "  Document(id='7e717c8e-2008-41c4-a1c0-d892d1df4bb8', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\nAnother quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\\nSelf-Reflection#')],\n",
       " [Document(id='7e717c8e-2008-41c4-a1c0-d892d1df4bb8', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\nAnother quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\\nSelf-Reflection#'),\n",
       "  Document(id='e8c5ef63-cdfa-4cd1-ab93-810c333cc4db', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Component One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.')]]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_retriever.invoke(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f9926f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a RAG-fusion to fusion our documents\n",
    "def rag_fusion(documents : List[List[Document]]) -> List[Document]:\n",
    "    # documents_dict: key = id, value = document\n",
    "    # RRF_score_dict: key = id, value = \n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
